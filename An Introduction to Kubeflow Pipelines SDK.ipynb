{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T19:33:52.236268Z",
     "iopub.status.busy": "2022-04-25T19:33:52.235957Z",
     "iopub.status.idle": "2022-04-25T19:33:52.239999Z",
     "shell.execute_reply": "2022-04-25T19:33:52.239338Z",
     "shell.execute_reply.started": "2022-04-25T19:33:52.236194Z"
    },
    "tags": []
   },
   "source": [
    "# An Introduction to Kubeflow Pipelines SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "I like to put all my imports at the top of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp import compiler\n",
    "\n",
    "from random import SystemRandom\n",
    "from string import ascii_lowercase as lc\n",
    "\n",
    "rand = SystemRandom()\n",
    "\n",
    "\n",
    "def upload_pipeline(client: kfp.Client, metadata: dict, pipeline_function):\n",
    "    \n",
    "    compiler.Compiler().compile(\n",
    "        pipeline_function,\n",
    "        metadata.get(\"pipeline_package_path\"))\n",
    "\n",
    "    return client.upload_pipeline(\n",
    "        metadata.get(\"pipeline_package_path\"),\n",
    "        metadata.get(\"pipeline_name\"))\n",
    "\n",
    "\n",
    "def random_string():\n",
    "    return ''.join(rand.choice(lc) for _ in range(4))\n",
    "\n",
    "\n",
    "def experiment_metadata(\n",
    "    namespace: str,\n",
    "    experiment_name: str,\n",
    "    experiment_description: str,\n",
    "    pipeline_name: str,\n",
    "    pipeline_description: str\n",
    "):\n",
    "    \"\"\"Create Metadata for Kubeflow Pipeline Experiment.\"\"\"\n",
    "\n",
    "    _namespace = namespace.lower().replace(\" \", \"-\")\n",
    "    _experiment_name = f\"{namespace}-{experiment_name}\".lower().replace(\" \", \"-\")\n",
    "    _experiment_description = experiment_description\n",
    "    _pipeline_name = f\"{_experiment_name}-{pipeline_name}-{random_string()}\".lower().replace(\" \", \"-\")\n",
    "    _pipeline_description = pipeline_description\n",
    "    _run_name = f\"{time.strftime('%Y%m%d-%H%M%S')}-{_pipeline_name}\"\n",
    "    _pipeline_package_path = f\"{_run_name}.yaml.zip\"\n",
    "\n",
    "    print(\"--------------------------\")\n",
    "    print(\"Metadata\")\n",
    "    print(\"--------------------------\")\n",
    "    print(\"Namespace\")\n",
    "    print(f\"Name:\\t\\t{_namespace}\")\n",
    "    print(\"--------------------------\")\n",
    "    print(\"Experiment\")\n",
    "    print(f\"Name:\\t\\t{_experiment_name}\")\n",
    "    print(f\"Description:\\t{_experiment_description}\")\n",
    "    print(\"--------------------------\")\n",
    "    print(\"Pipeline\")\n",
    "    print(f\"Name:\\t\\t{_pipeline_name}\")\n",
    "    print(f\"Description:\\t{_pipeline_description}\")\n",
    "    print(f\"Zipped YAML:\\t{_pipeline_package_path}\")\n",
    "    print(\"--------------------------\")\n",
    "    print(\"Run\")\n",
    "    print(f\"Name:\\t\\t{_run_name}\")\n",
    "    print(\"--------------------------\")\n",
    "\n",
    "    return {\n",
    "        \"namespace\": _namespace,\n",
    "        \"experiment_name\": _experiment_name,\n",
    "        \"experiment_description\": _experiment_description,\n",
    "        \"pipeline_name\": _pipeline_name,\n",
    "        \"pipeline_description\": _pipeline_description,\n",
    "        \"run_name\": _run_name,\n",
    "        \"pipeline_package_path\": _pipeline_package_path\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata\n",
    "\n",
    "Fill out the metadata for the run, pipeline and experiment!\n",
    "\n",
    "1. `namespace`: Your namespace.\n",
    "1. `experiment_name`: Your pipelines are run in an experiment. Give your experiment a unique and descriptive name.\n",
    "1. `experiment_description`: You should provide a short description, it will be a gift to your future self.\n",
    "1. `pipeline_name`: Name your pipeline. Must be unique. Try to be descriptive.\n",
    "1. `pipeline_description`: The more metadata the better!\n",
    "1. `pipeline_package_path`: This is the location of the zipped YAML containing the description of the pipeline.\n",
    "1. `run_name`: The run's name is automatically generated by concatenating the `experiment_name`, `pipeline_name` and today's time/date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fill in the following 5 metadata fields:\n",
    "\n",
    "namespace = \"bryanpaget\"\n",
    "\n",
    "experiment_name = \"Introduction to Kubeflow Pipelines Python SDK!\"\n",
    "experiment_description = \"The Kubeflow Pipelines SDK provides a set of Python packages that you can use to specify and run your machine learning (ML) workflow as a pipeline.\"\n",
    "\n",
    "pipeline_name = \"Simple Pipeline\"\n",
    "pipeline_description = \"Just an Example Pipeline.\"\n",
    "\n",
    "# -------------------------------------------------\n",
    "\n",
    "# Metadata is created here:\n",
    "metadata = experiment_metadata(\n",
    "    namespace, experiment_name, experiment_description,\n",
    "    pipeline_name, pipeline_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Parameters\n",
    "\n",
    "This is where you populate a dictionary with your pipeline's parameters. For this simple example we just need a dictionary of 5 integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_parameters = {\n",
    "    'a': 5,\n",
    "    'b': 5,\n",
    "    'c': 8,\n",
    "    'd': 10,\n",
    "    'e': 18\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Operator\n",
    "\n",
    "This is a simple operator for Kubeflow. For the next demo I'll do something more interesting. In the mean time here is the documentation on writing your own components. https://www.kubeflow.org/docs/components/pipelines/sdk/component-development/#writing-your-component-definition-file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def average_op(*numbers):\n",
    "    \"\"\"\n",
    "    Factory for average ContainerOps: accepts an arbitrary number of input numbers,\n",
    "    returning a ContainerOp that passes those numbers to the underlying Docker image\n",
    "    for averaging.\n",
    "\n",
    "    For dsl.ContainerOp:\n",
    "\n",
    "        name (String): What will show up on the pipeline viewer.\n",
    "        image (String): The container image that KFP runs to do the work.\n",
    "        command (List): Put the commands for the container here.\n",
    "        arguments (Dictionary): Passes each number as a separate command line argument.\n",
    "                                Note that these arguments get serialized to strings\n",
    "        file_outputs (Dictionary): Expect an output file called out.txt to be\n",
    "                                   generated KFP can read this file and bring it back automatically\n",
    "\n",
    "    Returns: output collected from ./out.txt from inside the container\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if len(numbers) < 1:\n",
    "        raise ValueError(\"You must specify at least one number to average.\")\n",
    "\n",
    "    return dsl.ContainerOp(\n",
    "        name=\"average\",\n",
    "        image=\"k8scc01covidacr.azurecr.io/kfp-components/average:v1\",\n",
    "        command=[\"python\", \"average.py\"],\n",
    "        arguments=numbers,\n",
    "        file_outputs={'data': './out.txt'}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "This is where the pipeline is created using the `@dsl.pipeline` decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=pipeline_name, description=pipeline_description)\n",
    "def pipeline(a, b, c, d, e):\n",
    "    avg_1 = average_op(a, b)\n",
    "    avg_2 = average_op(d, e)\n",
    "    avg_3 = average_op(avg_1.output, avg_1.output)\n",
    "    average_result_overall = average_op(c, avg_3.output, avg_2.output)\n",
    "    print(average_result_overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T19:43:10.983738Z",
     "iopub.status.busy": "2022-04-25T19:43:10.983485Z",
     "iopub.status.idle": "2022-04-25T19:43:10.987774Z",
     "shell.execute_reply": "2022-04-25T19:43:10.987166Z",
     "shell.execute_reply.started": "2022-04-25T19:43:10.983713Z"
    }
   },
   "source": [
    "## Publish Pipeline and Run Pipeline in an Experiment\n",
    "\n",
    "The experiment is created once a connection is established to the KFP client. The pipeline is compiled and then run inside the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = kfp.Client()\n",
    "\n",
    "response = upload_pipeline(client, metadata, pipeline)\n",
    "\n",
    "try:\n",
    "    experiment = client.get_experiment(\n",
    "        name=experiment_name,\n",
    "        description=experiment_description,\n",
    "        namespace=namespace)\n",
    "except:\n",
    "    experiment = client.create_experiment(\n",
    "        name=experiment_name,\n",
    "        description=experiment_description,\n",
    "        namespace=namespace)\n",
    "\n",
    "run = client.run_pipeline(\n",
    "    experiment_id=experiment.id,\n",
    "    job_name=metadata.get(\"run_name\"),\n",
    "    pipeline_package_path=metadata.get(\"pipeline_package_path\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
